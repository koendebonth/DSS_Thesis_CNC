{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import depencies\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    # Get the current working directory\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    # Set the root directory to the parent of the current directory\n",
    "    root_dir = Path(current_dir).parent\n",
    "\n",
    "    # Add the root directory to sys.path so Python can find the utils module\n",
    "    sys.path.append(str(root_dir))\n",
    "    print(f\"Added {root_dir} to Python path\")\n",
    "\n",
    "    # Standard libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import itertools\n",
    "    import h5py\n",
    "\n",
    "    # Data processing and visualization\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from scipy import signal, stats\n",
    "    import pywt\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    # Machine learning\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    # Custom utilities\n",
    "    from utils import data_loader_utils\n",
    "    from utils.feature_extraction import transform_data\n",
    "    from utils.load_data import load_data\n",
    "    from utils.result_utils import create_results_df, record_result\n",
    "\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    print(\"Dependencies loaded successfully âœ…\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dependencies: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 == good | 1 == bad |\n",
    "X, y, y_binary = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_RF = create_results_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainy, testy = train_test_split(X, y_binary, test_size=0.2, random_state=42, stratify=y_binary)\n",
    "\n",
    "print(f\"Train set size: {len(trainX)} samples\")\n",
    "print(f\"Test set size: {len(testX)} samples\")\n",
    "\n",
    "# transform and resample\n",
    "trainX_tr, trainy_tr = transform_data(trainX, trainy, label_type='binary')\n",
    "\n",
    "smote = SMOTE(k_neighbors=5, random_state=42)\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "trainX_tr, trainy_tr = rus.fit_resample(trainX_tr, trainy_tr)\n",
    "trainX_tr_resampled, trainy_tr_resampled = smote.fit_resample(trainX_tr, trainy_tr)\n",
    "testX_tr, testy_tr = transform_data(testX, testy, label_type='binary')\n",
    "\n",
    "    # Train Random Forest classifier with optimized hyperparameters\n",
    "RF = RandomForestClassifier(max_features='log2', \n",
    "                            n_estimators=150,\n",
    "                            max_depth=15,\n",
    "                            min_samples_leaf=1,\n",
    "                            min_samples_split=2,\n",
    "                            random_state=42)\n",
    "\n",
    "RF.fit(trainX_tr_resampled, trainy_tr_resampled)\n",
    "\n",
    "# Evaluate the model\n",
    "yhat = RF.predict(testX_tr)\n",
    "score = f1_score(testy_tr, yhat, pos_label=1, average='binary')\n",
    "cm = confusion_matrix(testy_tr, yhat).ravel()\n",
    "# record results\n",
    "record_result(result_df_RF, 0, 0, 0, trainy, trainy_tr_resampled, testy, score, cm, experiment_id='exp0_no_machine_adoption_random_split')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(m01, m02, m03,show_confusion_matrix=False):\n",
    "    '''Run one-class SVM experiment with specified machine fractions.'''   \n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y_binary)\n",
    "\n",
    "    machine_train_frac = {'M01': m01, 'M02': m02, 'M03': m03}\n",
    "    trainX, trainy, testX, testy = [], [], [], []\n",
    "    \n",
    "    for machine, frac in machine_train_frac.items():\n",
    "        # filter samples for this machine\n",
    "        data = [(x_i, y_i) for x_i, y_i in zip(Xtrain, ytrain)]\n",
    "        X_m = [d[0] for d in data if d[1].split('_')[0] == machine]\n",
    "        y_m = [0 if d[1].split('_')[-1] == 'good' else 1 for d in data if d[1].split('_')[0] == machine]\n",
    "        if frac == 1.0:\n",
    "            trainX.extend(X_m); trainy.extend(y_m)\n",
    "        elif frac == 0.0:\n",
    "            testX.extend(X_m); testy.extend(y_m)\n",
    "        else:\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "                X_m, y_m, train_size=frac, stratify=y_m, random_state=42\n",
    "            )\n",
    "            trainX.extend(X_tr); trainy.extend(y_tr)\n",
    "            testX.extend(X_te); testy.extend(y_te)\n",
    "\n",
    "    # transform and resample\n",
    "    trainX_tr, trainy_tr = transform_data(trainX, trainy)\n",
    "    testX_tr, testy_tr = transform_data(Xtest, ytest,label_type='string')\n",
    "\n",
    "    # print(f\"Class distribution before resampling: {pd.Series(trainy_tr).value_counts()}\")\n",
    "    \n",
    "    rus = RandomUnderSampler(sampling_strategy=0.25, random_state=42)\n",
    "\n",
    "    trainX_tr, trainy_tr = rus.fit_resample(trainX_tr, trainy_tr)\n",
    "    \n",
    "    smote = SMOTE(random_state=42)\n",
    "    trainX_tr_resampled, trainy_tr_resampled = smote.fit_resample(trainX_tr, trainy_tr)\n",
    "    \n",
    "    RF = RandomForestClassifier(max_features='log2', \n",
    "                                n_estimators=150,\n",
    "                                max_depth=15,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_samples_split=2,\n",
    "                                random_state=42,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "    RF.fit(trainX_tr_resampled, trainy_tr_resampled)\n",
    "\n",
    "    yhat = RF.predict(testX_tr)\n",
    "    score = f1_score(testy_tr, yhat, pos_label=1, average='binary')\n",
    "    cm = confusion_matrix(testy_tr, yhat)\n",
    "\n",
    "    record_result(result_df_RF, m01, m02, m03, trainy, trainy_tr_resampled, testy, score, cm)\n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        return ConfusionMatrixDisplay.from_estimator(RF, testX_tr, testy_tr)\n",
    "\n",
    "# e.g. experiment 1: vary M02\n",
    "for m02 in np.arange(0, 0.51, 0.05):\n",
    "    run_experiment(1.0, m02, 0.0)\n",
    "    print(f\"Finished running experiment 1 (vary M02) with M02={m02:.2f}\")\n",
    "    result_df_RF.loc[result_df_RF.index[-1], 'experiment_id'] = 'exp1_vary_M02'\n",
    "\n",
    "# e.g. experiment 2: vary M03\n",
    "for m03 in np.arange(0.05, 0.51, 0.05):\n",
    "    run_experiment(1.0, 0.0, m03)\n",
    "    print(f\"Finished running experiment 2 (vary M03) with M03={m03:.2f}\")\n",
    "    result_df_RF.loc[result_df_RF.index[-1], 'experiment_id'] = 'exp2_vary_M03'\n",
    "\n",
    "# e.g. experiment 3: vary M02 and M03 together\n",
    "for frac in np.arange(0.05, 0.51, 0.05):\n",
    "    run_experiment(1.0, frac, frac)\n",
    "    print(f\"Finished running experiment 3 (vary both) with frac={frac:.2f}\")\n",
    "    result_df_RF.loc[result_df_RF.index[-1], 'experiment_id'] = 'exp3_vary_both'\n",
    "\n",
    "# Display the compiled results\n",
    "result_df_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.path.dirname(os.getcwd()), 'export')\n",
    "result_df_RF.to_csv(path + '/results/result_df_RF_0.25UND_SMOTE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(1.0, 0.5, 0.0,show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
