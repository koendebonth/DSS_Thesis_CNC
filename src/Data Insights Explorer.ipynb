{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSS Thesis - Koen de Bonth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Set the root directory to the parent of the current directory\n",
    "root_dir = Path(current_dir).parent\n",
    "\n",
    "# Add the root directory to sys.path so Python can find the utils module\n",
    "sys.path.append(str(root_dir))\n",
    "print(f\"Added {root_dir} to Python path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import data_loader_utils\n",
    "import itertools \n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pywt\n",
    "import numpy as np\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "machines = [\"M01\",\"M02\",\"M03\"]\n",
    "process_names = [\"OP00\",\"OP01\",\"OP02\",\"OP03\",\"OP04\",\"OP05\",\"OP06\",\"OP07\",\"OP08\",\"OP09\",\"OP10\",\"OP11\",\"OP12\",\"OP13\",\"OP14\"]\n",
    "labels = [\"good\",\"bad\"]\n",
    "\n",
    "path_to_dataset = os.path.join(root_dir, \"data\")\n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for process_name, machine, label in itertools.product(process_names, machines, labels):\n",
    "    data_path = os.path.join(path_to_dataset, machine, process_name, label)\n",
    "    data_list, data_label = data_loader_utils.load_tool_research_data(data_path, label=label)\n",
    "    X_data.extend(data_list)\n",
    "    y_data.extend(data_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store metadata about each h5 file\n",
    "file_metadata = []\n",
    "\n",
    "# Sampling rate in Hz for the measurements\n",
    "SAMPLING_RATE = 2000  \n",
    "\n",
    "for process_name, machine, label in itertools.product(process_names, machines, labels):\n",
    "    data_path = os.path.join(path_to_dataset, machine, process_name, label)\n",
    "    if os.path.exists(data_path):\n",
    "        for file in os.listdir(data_path):\n",
    "            if file.endswith('.h5'):\n",
    "                fullpath = os.path.join(data_path, file)\n",
    "                with h5py.File(fullpath, 'r') as f:\n",
    "                    dataset_name = list(f.keys())[0]\n",
    "                    dataset = f[dataset_name]\n",
    "                    \n",
    "                    file_metadata.append({\n",
    "                        'machine': machine,\n",
    "                        'operation': process_name,\n",
    "                        'class': label,\n",
    "                        'measurements': dataset.shape[0],\n",
    "                        'channels': dataset.shape[1] if len(dataset.shape) > 1 else 1,\n",
    "                        'duration_sec': dataset.shape[0] / SAMPLING_RATE,  # Duration in seconds\n",
    "                        'duration_min': dataset.shape[0] / SAMPLING_RATE / 60,  # Duration in minutes \n",
    "                        'file_size_mb': os.path.getsize(fullpath) / (1024 * 1024),\n",
    "                        'month_created': file.split('_')[1],\n",
    "                        'year_created': file.split('_')[2],\n",
    "                        'full_path': fullpath\n",
    "                    })\n",
    "\n",
    "# Create dataframe with file metadata\n",
    "df_measurement_files = pd.DataFrame(file_metadata)\n",
    "# df_measurement_files.to_csv('export/measurement_files_metadata.csv', index=False)\n",
    "\n",
    "# display(df_measurement_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coif8 en db14 over elkaar voor vergelijking\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "signal = x[100][:2000, 0]  # Gebruik zelfde signaal als hierboven\n",
    "\n",
    "# Bereken wavelet decomposities\n",
    "coif8_coeffs = pywt.wavedec(signal, wavelet='coif8', level=3)\n",
    "db14_coeffs = pywt.wavedec(signal, wavelet='db14', level=3)\n",
    "\n",
    "# Reconstrueer approximaties\n",
    "coif8_reconstructed = pywt.waverec([coif8_coeffs[0]] + [None] * 3, 'coif8')\n",
    "db14_reconstructed = pywt.waverec([db14_coeffs[0]] + [None] * 3, 'db14')\n",
    "\n",
    "# Plot beide reconstructies over elkaar\n",
    "plt.plot(coif8_reconstructed[:len(signal)], label='coif8', alpha=0.7)\n",
    "plt.plot(db14_reconstructed[:len(signal)], label='db14', alpha=0.7)\n",
    "plt.title(\"Vergelijking van coif8 en db14 wavelet reconstructies (level 3)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Voeg wat nuttige analyses toe\n",
    "print(\"\\nSamenvatting van de dataset:\")\n",
    "print(f\"Totaal aantal files: {len(df_measurement_files)}\")\n",
    "print(f\"\\nGemiddelde duur per meting: {df_measurement_files['duration_sec'].mean():.2f} seconden\")\n",
    "print(f\"Standaard deviatie van duur: {df_measurement_files['duration_sec'].std():.2f} seconden\")\n",
    "print(f\"\\nAantal kanalen per meting: {df_measurement_files['channels'].value_counts().to_dict()}\")\n",
    "\n",
    "# Visualisatie van de duur van metingen\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(df_measurement_files['duration_sec'], bins=50)\n",
    "plt.title('Distributie van meting duraties')\n",
    "plt.xlabel('Duratie (seconden)')\n",
    "plt.ylabel('Aantal files')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot van duur per operatie\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.boxplot(data=df_measurement_files, x='operation', y='duration_sec')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Duratie per operatie')\n",
    "plt.xlabel('Operatie')\n",
    "plt.ylabel('Duratie (seconden)')\n",
    "plt.show()\n",
    "\n",
    "# Maak een bar plot van de verdeling van de data over machines, operaties en klassen\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Maak een figuur met subplots\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot voor machine verdeling\n",
    "df_measurement_files['machine'].value_counts().plot(kind='bar', ax=ax1)\n",
    "ax1.set_title('Aantal samples per machine')\n",
    "ax1.set_xlabel('Machine')\n",
    "ax1.set_ylabel('Aantal samples')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot voor operatie verdeling \n",
    "df_measurement_files['operation'].value_counts().plot(kind='bar', ax=ax2)\n",
    "ax2.set_title('Aantal samples per operatie')\n",
    "ax2.set_xlabel('Operatie')\n",
    "ax2.set_ylabel('Aantal samples')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot voor klasse verdeling\n",
    "df_measurement_files['class'].value_counts().plot(kind='bar', ax=ax3)\n",
    "ax3.set_title('Aantal samples per klasse')\n",
    "ax3.set_xlabel('Klasse')\n",
    "ax3.set_ylabel('Aantal samples')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot voor operatie verdeling \n",
    "df_measurement_files['operation'].value_counts().plot(kind='bar', ax=ax2)\n",
    "ax2.set_title('Aantal samples per operatie')\n",
    "ax2.set_xlabel('Operatie')\n",
    "ax2.set_ylabel('Aantal samples')\n",
    "\n",
    "# Plot voor klasse verdeling\n",
    "df_measurement_files['class'].value_counts().plot(kind='bar', ax=ax3)\n",
    "ax3.set_title('Aantal samples per klasse')\n",
    "ax3.set_xlabel('Klasse')\n",
    "ax3.set_ylabel('Aantal samples')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Export the plot to a file\n",
    "# fig.savefig('data_distribution.png')\n",
    "\n",
    "# Print wat statistieken\n",
    "print(\"\\nDataset statistieken:\")\n",
    "print(f\"Totaal aantal samples: {len(df_measurement_files)}\")\n",
    "print(\"\\nVerdeling per machine:\")\n",
    "print(df_measurement_files['machine'].value_counts())\n",
    "print(\"\\nVerdeling per operatie:\")\n",
    "print(df_measurement_files['operation'].value_counts())\n",
    "print(\"\\nVerdeling per klasse:\")\n",
    "print(df_measurement_files['class'].value_counts())\n",
    "\n",
    "\n",
    "print(\"mean:\",df_measurement_files['measurements'].mean())\n",
    "print(\"std:\",df_measurement_files['measurements'].std())\n",
    "print(\"median:\",df_measurement_files['measurements'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
