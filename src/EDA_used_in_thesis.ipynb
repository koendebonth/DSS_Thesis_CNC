{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Transfer Learning\n",
    "\n",
    "Dit notebook bevat de analyse en training waarbij een model wordt getraind op machine 1 en vervolgens wordt getest en gevalideerd op machine 2 en 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Zorg ervoor dat figuren groot genoeg zijn\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Directory setup\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "export_dir = os.path.join(root_dir, 'export')\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(os.path.join(export_dir, 'measurement_files_metadata.csv'))\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verdeling van data over machines\n",
    "\n",
    "Laten we eerst de verdeling van de data over de machines bekijken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verdeling van samples over machines\n",
    "machine_dist = pd.crosstab(\n",
    "    [df['machine'], df['operation']], \n",
    "    df['class']\n",
    ").assign(Total=lambda x: x.sum(axis=1)).sort_index()\n",
    "\n",
    "# print(\"Verdeling van samples over machines:\")\n",
    "# display(machine_dist)\n",
    "\n",
    "# Maak een visualisatie\n",
    "plt.figure(figsize=(15, 10))\n",
    "machine_dist.reset_index().pivot(index='operation', columns='machine', values='Total').plot(kind='bar')\n",
    "plt.title('Aantal samples per machine en bewerking')\n",
    "plt.ylabel('Aantal samples')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Machine')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(export_dir, 'machine_distribution.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal analasys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Set the root directory to the parent of the current directory\n",
    "root_dir = Path(current_dir).parent\n",
    "\n",
    "# Add the root directory to sys.path so Python can find the utils module\n",
    "sys.path.append(str(root_dir))\n",
    "print(f\"Added {root_dir} to Python path\")\n",
    "\n",
    "os.chdir(Path(os.getcwd()).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader_utils import datafile_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OP07_BAD_M01 = datafile_read('data/M01/OP07/bad/M01_Aug_2019_OP07_000.h5',axes=[0])\n",
    "OP07_BAD_M02 = datafile_read('data/M02/OP07/bad/M02_Aug_2019_OP07_000.h5',axes=[0])\n",
    "OP07_BAD_M03 = datafile_read('data/M03/OP07/bad/M03_Aug_2019_OP07_000.h5',axes=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "def wavelet_transform(signal, wavelet='coif8', maxlevel=3, mode='symmetric'):\n",
    "    return pywt.WaveletPacket(data=signal, wavelet=wavelet, maxlevel=maxlevel, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for i in range(3):\n",
    "        machine_data = datafile_read(f'data/M0{i+1}/OP07/bad/M0{i+1}_Aug_2019_OP07_000.h5',axes=[j],plotting=False)\n",
    "        wp_data = wavelet_transform(machine_data[:,0])\n",
    "        plt.plot(wp_data['aaa'].data, label=f'Machine M0{i+1}')\n",
    "    plt.title(f'Wavelet Packet Decomposition - AAA Node - Axis {j}')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OP07_BAD_M01_WP = wavelet_transform(OP07_BAD_M01[:,0])  \n",
    "OP07_BAD_M02_WP = wavelet_transform(OP07_BAD_M02[:,0])\n",
    "OP07_BAD_M03_WP = wavelet_transform(OP07_BAD_M03[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cross-correlation between signals of the three machines\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract axis 0 data for each machine\n",
    "m1_data = OP07_BAD_M01_WP['aaa'].data\n",
    "m2_data = OP07_BAD_M02_WP['aaa'].data \n",
    "m3_data = OP07_BAD_M03_WP['aaa'].data\n",
    "\n",
    "# Find minimum length across all signals\n",
    "min_length = min(len(m1_data), len(m2_data), len(m3_data))\n",
    "\n",
    "# Truncate signals to minimum length\n",
    "m1_data = m1_data[:min_length]\n",
    "m2_data = m2_data[:min_length] \n",
    "m3_data = m3_data[:min_length]\n",
    "\n",
    "# Calculate cross-correlations\n",
    "cross_corr_m1_m2 = signal.correlate(m1_data, m2_data, mode='same') / np.sqrt(signal.correlate(m1_data, m1_data, mode='same')[int(min_length/2)] * signal.correlate(m2_data, m2_data, mode='same')[int(min_length/2)])\n",
    "cross_corr_m1_m3 = signal.correlate(m1_data, m3_data, mode='same') / np.sqrt(signal.correlate(m1_data, m1_data, mode='same')[int(min_length/2)] * signal.correlate(m3_data, m3_data, mode='same')[int(min_length/2)])\n",
    "cross_corr_m2_m3 = signal.correlate(m2_data, m3_data, mode='same') / np.sqrt(signal.correlate(m2_data, m2_data, mode='same')[int(min_length/2)] * signal.correlate(m3_data, m3_data, mode='same')[int(min_length/2)])\n",
    "\n",
    "# Create lag array for plotting\n",
    "lags = np.arange(-min_length/2, min_length/2)\n",
    "\n",
    "# Plot cross-correlations\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(lags, cross_corr_m1_m2, label='M01-M02')\n",
    "plt.plot(lags, cross_corr_m1_m3, label='M01-M03')\n",
    "plt.plot(lags, cross_corr_m2_m3, label='M02-M03')\n",
    "plt.title('Cross-Correlation between Machine Signals - Axis 0')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Also create a matrix to show maximum cross-correlation values\n",
    "max_corr_values = np.array([\n",
    "    [1, np.max(cross_corr_m1_m2), np.max(cross_corr_m1_m3)],\n",
    "    [np.max(cross_corr_m1_m2), 1, np.max(cross_corr_m2_m3)],\n",
    "    [np.max(cross_corr_m1_m3), np.max(cross_corr_m2_m3), 1]\n",
    "])\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.heatmap(max_corr_values, annot=True, cmap='coolwarm', \n",
    "            xticklabels=['M01', 'M02', 'M03'],\n",
    "            yticklabels=['M01', 'M02', 'M03'])\n",
    "plt.title('Maximum Cross-Correlation Values')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
