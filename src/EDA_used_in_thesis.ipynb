{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Transfer Learning\n",
    "\n",
    "Dit notebook bevat de analyse en training waarbij een model wordt getraind op machine 1 en vervolgens wordt getest en gevalideerd op machine 2 en 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import random\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Sequence, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pywt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Zorg ervoor dat figuren groot genoeg zijn\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "df = pd.read_csv('export\\measurement_files_metadata.csv')\n",
    "display(df)\n",
    "\n",
    "export_dir = 'export'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verdeling van data over machines\n",
    "\n",
    "Laten we eerst de verdeling van de data over de machines bekijken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verdeling van samples over machines\n",
    "machine_dist = pd.crosstab(\n",
    "    [df['machine'], df['operation']], \n",
    "    df['class']\n",
    ").assign(Total=lambda x: x.sum(axis=1)).sort_index()\n",
    "\n",
    "# print(\"Verdeling van samples over machines:\")\n",
    "# display(machine_dist)\n",
    "\n",
    "# Maak een visualisatie\n",
    "plt.figure(figsize=(15, 10))\n",
    "machine_dist.reset_index().pivot(index='operation', columns='machine', values='Total').plot(kind='bar')\n",
    "plt.title('Aantal samples per machine en bewerking')\n",
    "plt.ylabel('Aantal samples')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Machine')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(export_dir, 'machine_distribution.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a custom font file if you have one (optional)\n",
    "# from matplotlib import font_manager\n",
    "# font_manager.fontManager.addfont('/path/to/OpenSans-Regular.ttf')\n",
    "\n",
    "# 1) Set global font family and fallbacks\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = [\n",
    "    'Open Sans', 'Lato', 'Arial', 'DejaVu Sans'\n",
    "]\n",
    "\n",
    "# 2) Update overall styling\n",
    "sns.set_theme(\n",
    "    style='whitegrid',\n",
    "    palette='pastel',\n",
    "    rc={\n",
    "        'axes.titlesize': 16,\n",
    "        'axes.titleweight': 'bold',\n",
    "        'axes.labelsize': 14,\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12,\n",
    "        'font.size': 12\n",
    "    }\n",
    ")\n",
    "\n",
    "# Prepare data\n",
    "class_counts = df['class'].value_counts()\n",
    "total = class_counts.sum()\n",
    "colors = ['tab:green' if cls == 'good' else 'tab:red' for cls in class_counts.index]\n",
    "\n",
    "# Draw bars\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "bars = ax.bar(\n",
    "    class_counts.index,\n",
    "    class_counts.values,\n",
    "    color=colors,\n",
    "    edgecolor='gray',\n",
    "    linewidth=1.2,\n",
    "    width=0.6\n",
    ")\n",
    "\n",
    "# Annotate each bar with count and percentage\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    pct = height / total * 100\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + total * 0.005,\n",
    "        f\"{height:,}\\n({pct:.1f}%)\",\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontweight='medium'\n",
    "    )\n",
    "\n",
    "# Final touches\n",
    "ax.set_title('Distribution of Classes')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_ylim(0, class_counts.values.max() * 1.15)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(export_dir, 'class_distribution.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal analasys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Set the root directory to the parent of the current directory\n",
    "root_dir = Path(current_dir).parent\n",
    "\n",
    "# Add the root directory to sys.path so Python can find the utils module\n",
    "sys.path.append(str(root_dir))\n",
    "print(f\"Added {root_dir} to Python path\")\n",
    "\n",
    "os.chdir(Path(os.getcwd()).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Set the root directory to the parent of the current directory\n",
    "root_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "\n",
    "# Add the root directory to sys.path so Python can find the utils module\n",
    "sys.path.append(str(root_dir))\n",
    "\n",
    "from utils.data_loader_utils import datafile_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "file_paths = {\n",
    "    'M01': 'data/M01/OP07/bad/M01_Aug_2019_OP07_000.h5',\n",
    "    'M02': 'data/M02/OP07/bad/M02_Aug_2019_OP07_000.h5',\n",
    "    'M03': 'data/M03/OP07/bad/M03_Aug_2019_OP07_000.h5'\n",
    "}\n",
    "\n",
    "# Initialize variables\n",
    "OP07_BAD_M01, OP07_BAD_M02, OP07_BAD_M03 = None, None, None\n",
    "\n",
    "# Try to read files if they exist\n",
    "for machine, path in file_paths.items():\n",
    "    if os.path.exists(path):\n",
    "        if machine == 'M01':\n",
    "            OP07_BAD_M01 = datafile_read(path, axes=[0])\n",
    "            print(f\"Loaded {path}\")\n",
    "        elif machine == 'M02':\n",
    "            OP07_BAD_M02 = datafile_read(path, axes=[0])\n",
    "            print(f\"Loaded {path}\")\n",
    "        elif machine == 'M03':\n",
    "            OP07_BAD_M03 = datafile_read(path, axes=[0])\n",
    "            print(f\"Loaded {path}\")\n",
    "    else:\n",
    "        print(f\"Warning: File not found: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pywt.Wavelet('coif8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet = pywt.Wavelet('coif8')\n",
    "phi, psi, x = wavelet.wavefun(level=7)\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot scaling function\n",
    "ax1.plot(x, phi, linewidth=1.5, color='#1f77b4')\n",
    "ax1.set_title(\"Coiflet 8 – Scaling Function (φ)\", fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel(\"t\", fontsize=12)\n",
    "ax1.set_ylabel(\"φ(t)\", fontsize=12)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=11)\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# Plot wavelet function\n",
    "ax2.plot(x, psi, linewidth=1.5, color='#ff7f0e')\n",
    "ax2.set_title(\"Coiflet 8 – Wavelet Function (ψ)\", fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel(\"t\", fontsize=12)\n",
    "ax2.set_ylabel(\"ψ(t)\", fontsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=11)\n",
    "ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the figure to the export folder\n",
    "import os\n",
    "\n",
    "# Create export directory if it doesn't exist\n",
    "export_dir = \"../../export\"\n",
    "if not os.path.exists(export_dir):\n",
    "    os.makedirs(export_dir)\n",
    "\n",
    "# Save the figure\n",
    "fig_path = os.path.join(export_dir, \"coif8.png\")\n",
    "fig.savefig(fig_path, dpi=600, bbox_inches='tight')\n",
    "print(f\"Figure saved to {fig_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_transform(signal, wavelet='coif8', maxlevel=3, mode='symmetric'):\n",
    "    return pywt.WaveletPacket(data=signal, wavelet=wavelet, maxlevel=maxlevel, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for i in range(3):\n",
    "        machine_data = datafile_read(f'data/M0{i+1}/OP07/bad/M0{i+1}_Aug_2019_OP07_000.h5',axes=[j],plotting=False)\n",
    "        wp_data = wavelet_transform(machine_data[:,0])\n",
    "        plt.plot(wp_data['aaa'].data, label=f'Machine M0{i+1}')\n",
    "    plt.title(f'Wavelet Packet Decomposition - AAA Node - Axis {j}')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OP07_BAD_M01_WP = wavelet_transform(OP07_BAD_M01[:,0])  \n",
    "OP07_BAD_M02_WP = wavelet_transform(OP07_BAD_M02[:,0])\n",
    "OP07_BAD_M03_WP = wavelet_transform(OP07_BAD_M03[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cross-correlation between signals of the three machines\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract axis 0 data for each machine\n",
    "m1_data = OP07_BAD_M01_WP['aaa'].data\n",
    "m2_data = OP07_BAD_M02_WP['aaa'].data \n",
    "m3_data = OP07_BAD_M03_WP['aaa'].data\n",
    "\n",
    "# Find minimum length across all signals\n",
    "min_length = min(len(m1_data), len(m2_data), len(m3_data))\n",
    "\n",
    "# Truncate signals to minimum length\n",
    "m1_data = m1_data[:min_length]\n",
    "m2_data = m2_data[:min_length] \n",
    "m3_data = m3_data[:min_length]\n",
    "\n",
    "# Calculate cross-correlations\n",
    "cross_corr_m1_m2 = signal.correlate(m1_data, m2_data, mode='same') / np.sqrt(signal.correlate(m1_data, m1_data, mode='same')[int(min_length/2)] * signal.correlate(m2_data, m2_data, mode='same')[int(min_length/2)])\n",
    "cross_corr_m1_m3 = signal.correlate(m1_data, m3_data, mode='same') / np.sqrt(signal.correlate(m1_data, m1_data, mode='same')[int(min_length/2)] * signal.correlate(m3_data, m3_data, mode='same')[int(min_length/2)])\n",
    "cross_corr_m2_m3 = signal.correlate(m2_data, m3_data, mode='same') / np.sqrt(signal.correlate(m2_data, m2_data, mode='same')[int(min_length/2)] * signal.correlate(m3_data, m3_data, mode='same')[int(min_length/2)])\n",
    "\n",
    "# Create lag array for plotting\n",
    "lags = np.arange(-min_length/2, min_length/2)\n",
    "\n",
    "# Plot cross-correlations\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(lags, cross_corr_m1_m2, label='M01-M02')\n",
    "plt.plot(lags, cross_corr_m1_m3, label='M01-M03')\n",
    "plt.plot(lags, cross_corr_m2_m3, label='M02-M03')\n",
    "plt.title('Cross-Correlation between Machine Signals - Axis 0')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Also create a matrix to show maximum cross-correlation values\n",
    "max_corr_values = np.array([\n",
    "    [1, np.max(cross_corr_m1_m2), np.max(cross_corr_m1_m3)],\n",
    "    [np.max(cross_corr_m1_m2), 1, np.max(cross_corr_m2_m3)],\n",
    "    [np.max(cross_corr_m1_m3), np.max(cross_corr_m2_m3), 1]\n",
    "])\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.heatmap(max_corr_values, annot=True, cmap='coolwarm', \n",
    "            xticklabels=['M01', 'M02', 'M03'],\n",
    "            yticklabels=['M01', 'M02', 'M03'])\n",
    "plt.title('Maximum Cross-Correlation Values')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs. decomposed signal for Machine M01, Axis 0\n",
    "axis = 0\n",
    "original_signal   = OP07_BAD_M01[:, axis]\n",
    "decomposed_signal = OP07_BAD_M01_WP['aaa'].data\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Create two subplots stacked vertically\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "ax1.plot(original_signal, label='Original Signal (M01, Axis 0)', color='tab:blue')\n",
    "ax1.set_title('Original Signal')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "# ax1.legend()\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "ax2.plot(decomposed_signal, label='Wavelet Packet AAA Node', color='tab:orange')\n",
    "ax2.set_title('Decomposed Signal - Wavelet Packet AAA Node')\n",
    "ax2.set_xlabel('Sample')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "# ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the figure to the export directory\n",
    "fig.savefig(f'{export_dir}/wavelet_decomposition_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Figure saved to {export_dir}/wavelet_decomposition_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path to the current notebook directory\n",
    "current_dir = Path().resolve()\n",
    "\n",
    "# Set the project root directory (two levels up from notebooks if in experiments folder)\n",
    "project_root = current_dir.parent\n",
    "\n",
    "# Add the project root to sys.path so Python can find the utils module\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from utils.load_data import load_data\n",
    "from utils.feature_extraction import transform_data\n",
    "\n",
    "X,y, y_binary = load_data()\n",
    "# Group X and y by machine without forcing X into a 2D numpy array\n",
    "machines = ['M01', 'M02', 'M03']\n",
    "machine_data = {}\n",
    "\n",
    "for m in machines:\n",
    "    X_m = []\n",
    "    y_m = []\n",
    "    for xi, yi in zip(X, y):\n",
    "        if yi.startswith(f\"{m}_\"):\n",
    "            X_m.append(xi)  \n",
    "            y_m.append(0 if yi.endswith(\"_good\") else 1)\n",
    "\n",
    "    # leave X_m as a list of nd‐arrays; convert y_m to numpy if you like\n",
    "    machine_data[m] = (X_m, np.array(y_m))\n",
    "\n",
    "# e.g.:\n",
    "X_M01, y_M01 = machine_data['M01']\n",
    "X_M02, y_M02 = machine_data['M02']\n",
    "X_M03, y_M03 = machine_data['M03']\n",
    "\n",
    "X_M01_tr, y_M01_tr = transform_data(X_M01, y_M01, label_type='binary')\n",
    "X_M02_tr, y_M02_tr = transform_data(X_M02, y_M02, label_type='binary')\n",
    "X_M03_tr, y_M03_tr = transform_data(X_M03, y_M03, label_type='binary')\n",
    "\n",
    "# Create an overview of all the subsets\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(\"\\nMachine-specific breakdown:\")\n",
    "for machine in machines:\n",
    "    X_m, y_m = machine_data[machine]\n",
    "    good_samples = sum(1 for y in y_m if y == 0)\n",
    "    bad_samples = sum(1 for y in y_m if y == 1)\n",
    "    total_samples = len(y_m)\n",
    "    \n",
    "    print(f\"\\n{machine} Dataset:\")\n",
    "    print(f\"  Total samples: {total_samples}\")\n",
    "    print(f\"  Good samples: {good_samples} ({good_samples/total_samples:.2%})\")\n",
    "    print(f\"  Bad samples: {bad_samples} ({bad_samples/total_samples:.2%})\")\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a subplot for each machine\n",
    "for i, machine in enumerate(machines, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    _, y_m = machine_data[machine]\n",
    "    counts = np.bincount(y_m)\n",
    "    bars = plt.bar(['Good', 'Bad'], counts, color=['green', 'red'])\n",
    "    \n",
    "    # Add count labels on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{int(height)}',\n",
    "                 ha='center', va='bottom')\n",
    "    \n",
    "    plt.title(f'{machine} Class Distribution')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
